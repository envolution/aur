name: Grouped NVCHECKER Updates
on:
  schedule:
    - cron: '0 */12 * * *'  # Runs every 12 hours
  workflow_dispatch:  # Allows manual triggering

jobs:
  arch-task:
    runs-on: ubuntu-latest
    container:
      image: archlinux:latest
      options: --privileged # Required for system-level changes like useradd, pacman
    env:
        AUR_MAINTAINER_NAME: envolution
        GIT_USERNAME: envolution
        GIT_EMAIL: involution@gmail.com
        # For GITHUB_STEP_SUMMARY
        ACTIONS_STEP_SUMMARY: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}#step:${{ github.job }}:markdown-summary

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Initialize pacman keyring and update system
        run: |
          set -e 
          echo "::group::Initialize pacman and Update System"
          echo "Initializing pacman keyring..."
          mkdir -p /etc/pacman.d/gnupg
          pacman-key --init
          pacman-key --populate archlinux
          
          echo "Enabling multilib repository..."
          echo -e "\n[multilib]\nInclude = /etc/pacman.d/mirrorlist" >> /etc/pacman.conf
          
          echo "Updating system and installing core dependencies..."
          pacman -Sy --noconfirm --needed archlinux-keyring 
          pacman -Syu --noconfirm 
          
          echo "Installing necessary packages..."
          pacman -S --noconfirm --needed \
            git base-devel pacman-contrib openssh github-cli jq expac \
            ruby-rdoc ruby-pkg-config gnupg \
            python python-pip \
            pyalpm python-awesomeversion python-packaging python-lxml \
            python-gobject python-requests libnotify nvchecker \
            binutils multilib-devel python-aiohttp clang python-jq \
            sudo 
          echo "::endgroup::"

      - name: Setup non-root user for AUR operations
        shell: bash
        run: |
          set -e
          echo "::group::Setup non-root user 'builder'"
          echo "Creating build user 'builder'..."
          useradd -m -s /bin/bash builder 
          echo "builder ALL=(ALL) NOPASSWD: ALL" > /etc/sudoers.d/builder
          chmod 0440 /etc/sudoers.d/builder

          echo "Setting up directories for builder..."
          install -d -o builder -g builder -m 700 /home/builder/.gnupg 
          install -d -o builder -g builder -m 755 /home/builder/.cache
          install -d -o builder -g builder -m 755 /home/builder/.local
          install -d -o builder -g builder -m 755 /home/builder/.local/share
          install -d -o builder -g builder -m 755 /home/builder/.cache/paru
          install -d -o builder -g builder -m 755 /home/builder/.local/share/paru

          echo "Builder user setup complete."
          echo "::endgroup::"

      - name: Install paru (AUR helper)
        run: |
          set -e
          echo "::group::Install paru (AUR helper)"
          echo "Installing paru for 'builder' user..."
          cd /tmp
          sudo -u builder git clone https://aur.archlinux.org/paru-bin.git
          cd paru-bin
          sudo -u builder makepkg -si --noconfirm

          echo "Configuring paru..."
          echo -e "[options]\nBatchInstall\nBottomUp\nRemoveMake\nSudoLoop\nUseAsk" | sudo tee /etc/paru.conf > /dev/null
          
          echo "Paru installation and configuration complete."
          echo "::endgroup::"

      - name: Setup SSH key for AUR
        run: |
          set -e
          echo "::group::Setup SSH key for AUR"
          echo "Setting up SSH key for AUR access..."
          SSH_DIR="/home/builder/.ssh"
          mkdir -p "${SSH_DIR}"
          echo "${{ secrets.AUR_SSH_PRIVATE_KEY }}" > "${SSH_DIR}/aur"
          
          ssh-keyscan aur.archlinux.org >> "${SSH_DIR}/known_hosts"
          
          echo "Host aur.archlinux.org" >> "${SSH_DIR}/config"
          echo "  IdentityFile ${SSH_DIR}/aur" >> "${SSH_DIR}/config"
          echo "  User aur" >> "${SSH_DIR}/config" 
          echo "  StrictHostKeyChecking yes" >> "${SSH_DIR}/config"

          chown -R builder:builder "${SSH_DIR}"
          chmod 700 "${SSH_DIR}"
          chmod 600 "${SSH_DIR}/aur"
          chmod 600 "${SSH_DIR}/config" 
          chmod 644 "${SSH_DIR}/known_hosts"
          
          echo "SSH key setup complete. Permissions:"
          ls -ldn "${SSH_DIR}" "${SSH_DIR}/aur" "${SSH_DIR}/config" "${SSH_DIR}/known_hosts" # Use -n to show numeric UID/GID
          echo "::endgroup::"

      - name: Configure Git for builder user
        run: |
          set -e
          echo "::group::Configure Git for builder user"
          echo "Configuring Git for 'builder' user..."
          sudo -u builder git config --global user.name "${{ env.GIT_USERNAME }}"
          sudo -u builder git config --global user.email "${{ env.GIT_EMAIL }}"
          echo "Git configuration complete."
          echo "::endgroup::"

      - name: Run Arch Package Update and Build Task # Fix unbound array handling
        shell: bash
        run: |
          #!/bin/bash
          set -euo pipefail 
          echo "::notice title=SCRIPT_START::Arch Package Update Task started."

          # --- Helper Functions ---
          _log_notice() { echo "::notice title=$1::$2"; }
          _log_error() { echo "::error title=$1::$2"; }
          _log_warning() { echo "::warning title=$1::$2"; }
          _log_debug() { echo "::debug::$1"; } 
          _start_group() { echo "::group::$1"; }
          _end_group() { echo "::endgroup::"; }
          _log_notice "HELPER_DEF" "Helper functions defined."

          # --- Configuration & Constants ---
          _log_notice "VARS_CONSTANTS" "Defining constants..."
          BUILDER_HOME="/home/builder"; NVCHECKER_RUN_DIR="${BUILDER_HOME}/nvchecker-run"; ARTIFACTS_DIR="${GITHUB_WORKSPACE}/artifacts"; PACKAGE_DETAILS_JSON_PATH="${NVCHECKER_RUN_DIR}/package_details.json" 
          _log_notice "VARS_CONSTANTS" "BUILDER_HOME=${BUILDER_HOME}, NVCHECKER_RUN_DIR=${NVCHECKER_RUN_DIR}, PACKAGE_DETAILS_JSON_PATH=${PACKAGE_DETAILS_JSON_PATH}"
          
          # --- Function Definitions ---
          setup_environment() {
              _start_group "Setup Environment"; _log_notice "SETUP_ENV" "Configuring environment in ${NVCHECKER_RUN_DIR}..."
              if ! sudo -u builder mkdir -p "${NVCHECKER_RUN_DIR}"; then _log_error "SETUP_FAIL" "mkdir NVCHECKER_RUN_DIR failed."; _end_group; return 1; fi
              if ! mkdir -p "${ARTIFACTS_DIR}"; then _log_error "SETUP_FAIL" "mkdir ARTIFACTS_DIR failed."; _end_group; return 1; fi
              cd "${NVCHECKER_RUN_DIR}"; _log_debug "Now in $(pwd)."
              local all_ok=true
              for script_to_copy in "buildscript.py" "compare_aur_local_versions.py"; do 
                  local script_source_path; script_source_path=$(find "${GITHUB_WORKSPACE}/scripts/" -name "${script_to_copy}" -type f -print -quit 2>/dev/null)
                  if [ -n "${script_source_path}" ] && [ -f "${script_source_path}" ]; then
                      if sudo -u builder cp "${script_source_path}" "./${script_to_copy}" && sudo -u builder chmod +x "./${script_to_copy}"; then
                         _log_debug "Copied & chmodded ${script_to_copy}."
                      else _log_error "SETUP_FAIL" "cp/chmod failed for ${script_to_copy}."; all_ok=false; fi
                  else _log_error "SETUP_FAIL" "${script_to_copy} not found in ${GITHUB_WORKSPACE}/scripts/."; all_ok=false; fi
              done
              if ! ${all_ok}; then _log_error "SETUP_ENV_FINAL_FAIL" "Script setup failed."; _end_group; return 1; fi
              _log_notice "SETUP_ENV" "Environment setup SUCCEEDED."; _end_group; return 0 
          }

          generate_nvchecker_config() {
              _start_group "Generate NVChecker Configuration"; _log_notice "NV_CONF" "Generating nvchecker config files..."
              local cfg="new.toml"; local keyf="keyfile.toml"         
              echo "[__config__]" > "${cfg}"; echo "oldver = 'aur.json'" >> "${cfg}"; echo "newver = 'local.json'" >> "${cfg}" 
              echo "[keys]" > "${keyf}"; echo "github = '${{ secrets.GHuK }}'" >> "${keyf}"
              local individual_configs=(); mapfile -t individual_configs < <(find "${GITHUB_WORKSPACE}" -path "*/maintain/build/*/.nvchecker.toml" -type f -print)
              if [ ${#individual_configs[@]} -gt 0 ]; then
                  _log_debug "Appending ${#individual_configs[@]} individual .nvchecker.toml files."
                  for cf in "${individual_configs[@]}"; do cat "${cf}" >> "${cfg}"; echo "" >> "${cfg}"; done
              else _log_warning "NV_CONF" "No individual .nvchecker.toml files found."; fi
              if ! chown builder:builder "${cfg}" "${keyf}"; then _log_error "NV_CONF_FAIL" "chown for ${cfg}/${keyf} FAILED. Exit: $?."; _end_group; return 1; fi
              _log_notice "NV_CONF" "NVChecker configuration generated successfully."; _end_group; return 0
          }

          run_compare_aur_local_versions() {
              _start_group "Compare AUR vs Local Versions (Generates aur.json)"; _log_notice "COMPARE_AUR" "Running compare_aur_local_versions.py..."
              local script="./compare_aur_local_versions.py"; local outfile="aur.json" 
              if [ ! -f "${script}" ]; then _log_error "COMPARE_AUR_FAIL" "${script} not found in $(pwd)!"; _end_group; return 1; fi
              _log_debug "Executing: sudo -E -u builder python3 ${script} (args follow)"
              local stderr_log; stderr_log=$(mktemp)
              if sudo -E -u builder python3 "${script}" --maintainer "${AUR_MAINTAINER_NAME}" --repo-root "${GITHUB_WORKSPACE}" 2> "${stderr_log}"; then
                  if [ -s "${outfile}" ]; then 
                     _log_notice "COMPARE_AUR" "${outfile} generated (Size: $(wc -c < "${outfile}") bytes)."
                     _log_debug "aur.json Head: $(head -n 5 "${outfile}")"
                     if ! sudo -u builder chown builder:builder aur.json local.json changes.json combined.json 2>/dev/null; then _log_warning "COMPARE_AUR" "Could not chown one or more output files to builder."; fi
                  else _log_warning "COMPARE_AUR" "${outfile} was expected but is empty/not found."; if [ -s "${stderr_log}" ]; then _log_warning "COMPARE_AUR_PY_STDERR" "Stderr(exit 0): $(cat "${stderr_log}")"; fi; fi
              else
                  _log_error "COMPARE_AUR_FAIL" "Python script FAILED (Exit: $?). Stderr: $(cat "${stderr_log}")"; rm "${stderr_log}"; _end_group; return 1
              fi
              rm "${stderr_log}"; _log_notice "COMPARE_AUR" "compare_aur_local_versions.py SUCCEEDED."; _end_group; return 0
          }

          run_version_checks() {
              _start_group "Run Version Checks (nvchecker, nvcmp)"; _log_notice "VER_CHECKS" "Running nvchecker & nvcmp..."
              if [ ! -f "new.toml" ]||[ ! -f "keyfile.toml" ]||[ ! -f "aur.json" ]; then _log_error "VER_CHECKS_FAIL" "Missing input files."; _end_group; return 1; fi
              if sudo -E -u builder nvchecker -c new.toml -k keyfile.toml --logger json > local.json; then
                 _log_notice "VER_CHECKS" "nvchecker OK. local.json size: $(wc -c < local.json) bytes."; _log_debug "local.json Head: $(head -n 5 local.json)"
              else _log_error "VER_CHECKS_FAIL" "nvchecker FAILED (Exit: $?)."; _end_group; return 1; fi
              if sudo -E -u builder nvcmp -c new.toml > changes.json; then # This creates text changes.json
                 _log_notice "VER_CHECKS" "nvcmp OK. changes.json size: $(wc -c < changes.json) bytes."; _log_debug "changes.json Head: $(head -n 5 changes.json)"
              else _log_error "VER_CHECKS_FAIL" "nvcmp FAILED (Exit: $?)."; _end_group; return 1; fi
              _log_notice "VER_CHECKS" "Version checks SUCCEEDED."; _end_group; return 0
          }
          
          get_package_updates_list() {
              _start_group "Get Package Updates List"; 
              _log_notice "GET_UPDATES" "Determining packages to update using nvcmp -q only..."
              if [ ! -f "new.toml" ]; then _log_error "GET_UPDATES_FAIL" "new.toml not found for nvcmp -q!"; _end_group; return 1; fi
              local updates_from_nvcmp_q=()
              mapfile -t updates_from_nvcmp_q < <(sudo -E -u builder nvcmp -c new.toml -q 2>/dev/null || true)
              _log_debug "Found ${#updates_from_nvcmp_q[@]} updates from nvcmp -q."
              printf "  ::debug::updates_from_nvcmp_q: [%s]\n" "$(IFS=,; echo "${updates_from_nvcmp_q[*]}")"
              declare -ga UPDATES; 
              local temp_file_nvcmp_q; temp_file_nvcmp_q=$(mktemp)
              if [ ${#updates_from_nvcmp_q[@]} -gt 0 ]; then printf '%s\n' "${updates_from_nvcmp_q[@]}" > "${temp_file_nvcmp_q}"; else >"${temp_file_nvcmp_q}"; fi
              mapfile -t UPDATES < <(sort -u "${temp_file_nvcmp_q}" | grep .) 
              rm "${temp_file_nvcmp_q}"
              if [ ${#UPDATES[@]} -eq 0 ]; then _log_notice "GET_UPDATES" "No packages require updates based on nvcmp -q."
              else _log_notice "GET_UPDATES" "Found ${#UPDATES[@]} package(s) to update (from nvcmp -q):"; printf '  ::notice title=Update Candidate (nvcmp -q)::%s\n' "${UPDATES[@]}"; fi
              _log_notice "GET_UPDATES" "Package update list generation SUCCEEDED."; _end_group; return 0
          }

          extract_path_components() { 
              echo "::debug::extract_path_components input: $1" >&2 
              local path_to_parse="$1"; local relative_path="${path_to_parse#${GITHUB_WORKSPACE}/}"
              relative_path="${relative_path%/}";  relative_path="${relative_path#/}" 
              IFS='/' read -r -a components_array <<< "${relative_path}"
              echo "::debug::extract_path_components output: ${components_array[*]}" >&2 
              echo "${components_array[@]}" 
          }

          extract_pkgbuild_details() { 
              echo "::debug::extract_pkgbuild_details input (absolute PKGBUILD dir): $1" >&2 
              local pkgbuild_dir_abs="$1" 
              if [ ! -f "${pkgbuild_dir_abs}/PKGBUILD" ]; then 
                  echo "::error title=EXTRACT_FAIL::PKGBUILD missing in ${pkgbuild_dir_abs}" >&2
                  return 1
              fi
              ( 
                  CARCH="x86_64"; PKGDEST="/tmp/pkgdest"; SRCDEST="/tmp/srcdest"; SRCPKGDEST="/tmp/srcpkgdest"
                  source "${pkgbuild_dir_abs}/PKGBUILD" # Shellcheck source=/dev/null
                  declare -p depends makedepends checkdepends source 2>/dev/null || true 
              ) || 
              { 
                  echo "::error title=EXTRACT_FAIL::Sourcing/declaring PKGBUILD vars failed for ${pkgbuild_dir_abs}." >&2
                  return 1
              }
          }

          process_single_package_details() { 
              echo "::debug::process_single_package_details: pkg='$1', rel_dir='$2'" >&2
              local package_name="$1"; local pkgbuild_dir_rel_to_workspace="$2"; local declarations
              
              if ! declarations=$(extract_pkgbuild_details "${GITHUB_WORKSPACE}/${pkgbuild_dir_rel_to_workspace}"); then
                  echo "::error title=PROCESS_FAIL::extract_pkgbuild_details failed for ${package_name}." >&2
                  jq -n --arg pkg_name_arg "$package_name" '{($pkg_name_arg): {"error": "failed to extract PKGBUILD details"}}'
                  return 1 
              fi
              echo "::debug::Bash declarations for ${package_name} to be eval'd: ${declarations}" >&2
              
              unset depends makedepends checkdepends source 
              eval "$declarations" 
              
              local dep_j mak_j chk_j src_j 

              if declare -p depends &>/dev/null && [ ${#depends[@]} -gt 0 ]; then
                  dep_j=$(printf '%s\n' "${depends[@]}" | jq -R -s -c 'split("\n")[:-1]')
              else dep_j="[]"; fi

              if declare -p makedepends &>/dev/null && [ ${#makedepends[@]} -gt 0 ]; then
                  mak_j=$(printf '%s\n' "${makedepends[@]}" | jq -R -s -c 'split("\n")[:-1]')
              else mak_j="[]"; fi

              if declare -p checkdepends &>/dev/null && [ ${#checkdepends[@]} -gt 0 ]; then
                  chk_j=$(printf '%s\n' "${checkdepends[@]}" | jq -R -s -c 'split("\n")[:-1]')
              else chk_j="[]"; fi

              if declare -p source &>/dev/null && [ ${#source[@]} -gt 0 ]; then
                  src_j=$(printf '%s\n' "${source[@]}" | jq -R -s -c 'split("\n")[:-1]')
              else src_j="[]"; fi
              
              echo "::debug::JSON arrays for ${package_name}: depends=${dep_j}, makedepends=${mak_j}, checkdepends=${chk_j}, sources=${src_j}" >&2
              
              jq -n --arg pkg "$package_name" --argjson d "$dep_j" --argjson m "$mak_j" --argjson c "$chk_j" --argjson s "$src_j" \
                  '{($pkg): {depends: $d, makedepends: $m, checkdepends: $c, sources: $s}}'
          }

          # --- Main Execution Flow ---
          _log_notice "MAIN_EXEC" "Starting main execution flow..."
          
          if ! setup_environment; then _log_error "MAIN_FAIL" "setup_environment FAILED."; exit 1; fi
          if ! generate_nvchecker_config; then _log_error "MAIN_FAIL" "generate_nvchecker_config FAILED."; exit 1; fi
          if ! run_compare_aur_local_versions; then _log_error "MAIN_FAIL" "run_compare_aur_local_versions FAILED."; exit 1; fi
          if ! run_version_checks; then _log_error "MAIN_FAIL" "run_version_checks FAILED."; exit 1; fi
          if ! get_package_updates_list; then _log_error "MAIN_FAIL" "get_package_updates_list FAILED."; exit 1; fi

          _log_notice "MAIN_EXEC" "Pre-build phases completed. UPDATES count: ${#UPDATES[@]}"
          if [ ${#UPDATES[@]} -eq 0 ]; then
              _log_notice "MAIN_EXEC_NO_UPDATES" "No updates to process. Exiting."
              exit 0
          fi

          _start_group "Process PKGBUILD Details for Updated Packages"
          _log_notice "JSON_GEN" "Processing PKGBUILD details for ${#UPDATES[@]} updated package(s)..."
          
          combined_pkg_details_json="{}" 

          for package_to_process in "${UPDATES[@]}"; do
              _start_group "Processing Details: [${package_to_process}]" 
              _log_notice "JSON_GEN_PKG" "Starting detail extraction for: [${package_to_process}]"

              if [ -z "${package_to_process}" ]; then 
                  _log_warning "JSON_GEN_PKG_EMPTY_NAME" "package_to_process is empty. Skipping."
                  _end_group; continue
              fi
              
              pkg_build_dirs_found=() 
              mapfile -t pkg_build_dirs_found < <(find "${GITHUB_WORKSPACE}" -path "*/maintain/build/${package_to_process}" -type d -exec test -f "{}/PKGBUILD" \; -print)

              if [ ${#pkg_build_dirs_found[@]} -eq 0 ]; then
                  _log_warning "JSON_GEN_PKG_SKIP" "No PKGBUILD dir for '${package_to_process}'. Skipping."
                  _end_group; continue 
              elif [ ${#pkg_build_dirs_found[@]} -gt 1 ]; then
                  _log_warning "JSON_GEN_PKG_SKIP" "Multiple PKGBUILD dirs for '${package_to_process}'. Skipping."
                  _end_group; continue 
              fi
              
              package_dir_abs="${pkg_build_dirs_found[0]}" 
              package_dir_rel_to_workspace="${package_dir_abs#${GITHUB_WORKSPACE}/}" 
              _log_debug "Found PKGBUILD for ${package_to_process} at: ${package_dir_rel_to_workspace}"

              single_package_json_fragment="" 
              process_details_succeeded=true
              if ! single_package_json_fragment=$(process_single_package_details "$package_to_process" "$package_dir_rel_to_workspace"); then
                  _log_warning "JSON_GEN_PKG_PROCESS_FAIL" "process_single_package_details had issues for ${package_to_process} (fragment may contain error JSON)."
                  process_details_succeeded=false 
              fi
              _log_debug "JSON fragment for ${package_to_process}: ${single_package_json_fragment}"

              temp_merged_json="" 
              if temp_merged_json=$(jq -n --argjson current_json "$combined_pkg_details_json" --argjson fragment_json "$single_package_json_fragment" '$current_json + $fragment_json'); then
                 combined_pkg_details_json="$temp_merged_json" 
                 _log_debug "Merged JSON for ${package_to_process}."
                 if ! $process_details_succeeded; then _log_warning "JSON_GEN_PKG_MERGED_ERROR" "Merged JSON for ${package_to_process} (contained error field)."; fi
              else
                 _log_error "JSON_GEN_PKG_MERGE_FAIL" "jq merge FAILED for ${package_to_process}. Fragment: ${single_package_json_fragment}. Combined was: ${combined_pkg_details_json}"
              fi
              _end_group 
          done
          _log_notice "JSON_GEN_LOOP_END" "Finished loop over UPDATES array."

          _log_notice "JSON_GEN" "Saving combined package details to ${PACKAGE_DETAILS_JSON_PATH}..."
          echo "${combined_pkg_details_json}" | jq . > "${PACKAGE_DETAILS_JSON_PATH}"
          if chown builder:builder "${PACKAGE_DETAILS_JSON_PATH}"; then
             _log_debug "chown for ${PACKAGE_DETAILS_JSON_PATH} to builder SUCCEEDED."
          else _log_warning "JSON_GEN_CHOWN_FAIL" "Failed to chown ${PACKAGE_DETAILS_JSON_PATH} to builder."; fi
          
          _log_notice "JSON_GEN_SUMMARY" "Contents of ${PACKAGE_DETAILS_JSON_PATH} (first 20 lines):"
          head -n 20 "${PACKAGE_DETAILS_JSON_PATH}" | while IFS= read -r line; do _log_notice "JSON_LINE" "  $line"; done
          _log_debug "Full content of ${PACKAGE_DETAILS_JSON_PATH} (enable debug view):"; cat "${PACKAGE_DETAILS_JSON_PATH}" | while IFS= read -r line; do _log_debug "  $line"; done
          _end_group 

          _log_notice "SCRIPT_PHASED_END" "Current test phase (up to JSON generation) finished."
          
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          AUR_MAINTAINER_NAME: ${{ env.AUR_MAINTAINER_NAME }} 
